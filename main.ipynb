{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d153c1b-32f3-45ac-b859-08c144b3f04c",
   "metadata": {},
   "source": [
    "## News :D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8384fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import itertools\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b60b2c9",
   "metadata": {},
   "source": [
    "Installs:\n",
    "lxmn\n",
    "bs4\n",
    "pytorch\n",
    "\n",
    "# Currently:\n",
    "\n",
    "CNN has links by month\n",
    "\n",
    "NYT has links by day\n",
    "\n",
    "BI has links by month\n",
    "\n",
    "TH has links by day\n",
    "\n",
    "NYP has links by day\n",
    "\n",
    "DM has links by day\n",
    "\n",
    "Fox has links by page num\n",
    "\n",
    "## Thoughts on how to organize the data \n",
    "\n",
    "we use a pandas dataframe organized like this\n",
    "\n",
    "| Dates | CNN | NYT | BI | TH | NYP | DM | FOX |\n",
    "| ----------- | ------------------------------------------ | ------- | ------- | ------- | ------- | ------- | ------- |\n",
    "| 2014-01-01  | list of tuples with article link & title   | ... | ... | ... | ... | ... | ... |\n",
    "| 2014-01-02  | ... | ... | ... | ... | ... | ... | ... |\n",
    "| 2014-01-03  | ... | ... | ... | ... | ... | ... | ... |\n",
    "| 2014-01-04  | ... | ... | ... | ... | ... | ... | ... |\n",
    "| ...         | ... | ... | ... | ... | ... | ... | ... |\n",
    "| 2024-12-31  | ... | ... | ... | ... | ... | ... | ... |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a299259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [\n",
    "    \"January\",\n",
    "    \"February\",\n",
    "    \"March\",\n",
    "    \"April\",\n",
    "    \"May\",\n",
    "    \"June\",\n",
    "    \"July\",\n",
    "    \"August\",\n",
    "    \"September\",\n",
    "    \"October\",\n",
    "    \"November\",\n",
    "    \"December\",\n",
    "]\n",
    "mday = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "\n",
    "# CNN\n",
    "cnn_dict = dict(\n",
    "    [\n",
    "        (\n",
    "            i,\n",
    "            [\n",
    "                f\"https://www.cnn.com/article/sitemap-{i}-{j}.html\"\n",
    "                for j in range(1, 13)\n",
    "            ],\n",
    "        )\n",
    "        for i in range(2014, 2025)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# New York Times\n",
    "nyt_dict = dict(\n",
    "    [\n",
    "        (\n",
    "            i,\n",
    "            dict(\n",
    "                [\n",
    "                    (\n",
    "                        j,\n",
    "                        [\n",
    "                            f\"https://www.nytimes.com/sitemap/{i}/{str(j).zfill(2)}/{str(k).zfill(2)}/\"\n",
    "                            for k in range(1, mday[j - 1]+1)\n",
    "                        ],\n",
    "                    )\n",
    "                    for j in range(1, 13)\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "        for i in range(2014, 2025)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Business Insider\n",
    "bi_dict = dict(\n",
    "    [\n",
    "        (\n",
    "            i,\n",
    "            [\n",
    "                f\"https://www.businessinsider.com/sitemap/html/{i}-{str(j).zfill(2)}.html\"\n",
    "                for j in range(1, 13)\n",
    "            ],\n",
    "        )\n",
    "        for i in range(2014, 2025)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# The Hill\n",
    "th_dict = dict(\n",
    "    [\n",
    "        (\n",
    "            i,\n",
    "            dict(\n",
    "                [\n",
    "                    (\n",
    "                        months.index(j)+1,\n",
    "                        [\n",
    "                            f\"https://thehill.com/sitemap/{i}/{j}/{k}/\"\n",
    "                            for k in range(1, mday[months.index(j) - 1]+1)\n",
    "                        ],\n",
    "                    )\n",
    "                    for j in months\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "        for i in range(2014, 2025)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# New York Post\n",
    "nyp_dict = dict(\n",
    "    [\n",
    "        (\n",
    "            i,\n",
    "            dict(\n",
    "                [\n",
    "                    (\n",
    "                        j,\n",
    "                        [\n",
    "                            f\"https://nypost.com/{i}/{str(j).zfill(2)}/{str(k).zfill(2)}/\"\n",
    "                            for k in range(1, mday[j - 1]+1)\n",
    "                        ],\n",
    "                    )\n",
    "                    for j in range(1, 13)\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "        for i in range(2014, 2025)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Daily Mail\n",
    "dp_dict = dict(\n",
    "    [\n",
    "        (\n",
    "            i,\n",
    "            dict(\n",
    "                [\n",
    "                    (\n",
    "                        j,\n",
    "                        [\n",
    "                            f\"https://www.dailymail.co.uk/home/sitemaparchive/month_{i}{str(j).zfill(2)}{str(k).zfill(2)}.html\"\n",
    "                            for k in range(1, mday[j - 1]+1)\n",
    "                        ],\n",
    "                    )\n",
    "                    for j in range(1, 13)\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "        for i in range(2014, 2025)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Fox\n",
    "fox_links = [\"https://www.foxnews.com/sitemap.xml?type=articles\"] + [\n",
    "    f\"https://www.foxnews.com/sitemap.xml?type=articles&page={i}\"\n",
    "    for i in range(2, 161)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6073922",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241m.\u001b[39mget(cnn_dict[\u001b[38;5;241m2024\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      2\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(r\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m test \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mli\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "r = requests.get(cnn_dict[2024][0])\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "test = [i for i in soup.find_all(\"li\")]\n",
    "titles = []\n",
    "links = []\n",
    "dates = []\n",
    "for i in test:\n",
    "    for j in i.descendants:\n",
    "        if \"sitemap-link\" in str(j):\n",
    "            titles.append(\n",
    "                str(j)[\n",
    "                    36\n",
    "                    + str(j)[36:].index('\"')\n",
    "                    + 2 : 36\n",
    "                    + str(j)[36:].index(\"<\")\n",
    "                ]\n",
    "            )\n",
    "            links.append(str(j)[36 : 36 + str(j)[36:].index('\"')])\n",
    "        if \"date\" in str(j):\n",
    "            dates.append(str(j)[19:29])\n",
    "\n",
    "print(titles)\n",
    "print(links)\n",
    "print(dates)\n",
    "\n",
    "r = requests.get(nyt_dict[2024][1][0])\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "# print(r.text)\n",
    "test = [i for i in soup.find_all(\"li\")]\n",
    "titles = []\n",
    "links = []\n",
    "dates = []\n",
    "for i in test:\n",
    "    test = str(i.contents[0])\n",
    "    if (\"https:\" in test) & (\".html\" in test) & (\"2024/01/01\" in test):\n",
    "        links.append(test[test.index(\"https:\") : test.index(\".html\")])\n",
    "        titles.append(test[test.index(\">\") + 1 : test[4:].index(\"<\") + 4])\n",
    "        dates.append(\"2024-01-01\")\n",
    "\n",
    "print(titles)\n",
    "print(links)\n",
    "print(dates)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# <span class=\"sitemap-link\">\n",
    "# <li>\n",
    "# <span class=\"date\">2024-01-31</span><span class=\"sitemap-link\">\n",
    "# <a href=\"https://www.cnn.com/tech/live-news/meta-x-discord-tiktok-snap-chiefs-testimony-senate/index.html\">\n",
    "# Mark Zuckerberg apologizes to families over social media harms in contentious Senate hearing\n",
    "# </a>\n",
    "# </span>\n",
    "# </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02296371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Testing area\n",
    "import pandas as pd\n",
    "\n",
    "test_frame = pd.DataFrame()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
